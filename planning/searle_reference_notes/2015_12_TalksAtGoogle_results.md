Yes — the attached transcript of **John Searle’s 2015 “Talks at Google” lecture** provides strong textual support for the three epistemic limitations you outlined. Below is a detailed mapping of your three points to passages in the transcript, showing how Searle’s own words justify each claim.

---

## 1. “We don’t know what consciousness is”

Searle repeatedly emphasizes that **we lack a scientific understanding of consciousness** — that it’s a biological process we haven’t yet explained:

> “Thinking is a biological process created in the brain by certain quite complex, but insufficiently understood neurobiological processes.”
> “We don’t know how the brain does it, so we have no idea [how to create it artificially].”

He later summarizes:

> “We have no idea how to create a thinking machine because we don’t know how the brain does it.”

And again, during audience questions:

> “When they figure that out — and I don’t see any obstacle to figuring that out — it will be an enormous intellectual breakthrough, when we figure out how exactly the brain creates consciousness.”

So, Searle explicitly claims that the **nature and mechanism** of consciousness are unknown — matching your first epistemic limitation.

---

## 2. “We don’t know how to test for it”

Searle argues that **there’s no reliable empirical test for consciousness**, only indirect inference:

> “How do you know that a brain is conscious? How do you know that I’m conscious? … How do we know if a computer was conscious? … How do we measure that?”

He explains that we assume others are conscious by **analogy** with ourselves:

> “As far as human beings are concerned there isn’t any question that everybody in this room is conscious… It’s not even a theory that I hold. It’s a background presupposition.”

But crucially, he admits that for non-biological systems:

> “The question is, how do you know if a computer was conscious? We don’t have a computer today that seems conscious … but when we do, how do we know if it’s conscious or if it just seems conscious?”

This explicitly affirms your second epistemic limitation: **we lack a test for consciousness**, especially in artificial systems.

---

## 3. “We can’t determine it from behavioral observation”

Searle is clear that **behavioral equivalence does not imply consciousness** — this is the core lesson of the Chinese Room:

> “All the same, I don’t understand a word of Chinese. And there’s no way in the Chinese room that I could come to understand Chinese because all I am is a computer system.”

He draws the conclusion directly:

> “The bottom line is that the implemented computer program by itself is never going to be sufficient for human understanding because human understanding has more than syntax. It has a semantics.”

Later, when asked about tests like the Turing Test:

> “One bottom line of my whole discussion today is that the Turing test fails. It doesn’t give you a test of intelligence.”

This demonstrates that **behavioral tests** — such as passing the Turing Test — **cannot determine consciousness**. The system could behave *as if* it were conscious while lacking genuine awareness.

---

## Summary

| Your Claim                                  | Searle’s Supporting Statements                                                                  |
| ------------------------------------------- | ----------------------------------------------------------------------------------------------- |
| **1. We don’t know what consciousness is.** | “We don’t know how the brain does it.”; “It’s a biological process… insufficiently understood.” |
| **2. We don’t know how to test for it.**    | “How do we know if a computer was conscious? … How do we measure that?”                         |
| **3. We can’t determine it from behavior.** | “All I am is a computer system… The Turing test fails.”                                         |

---

### Conclusion

Yes — Searle’s 2015 *Talks at Google* lecture explicitly supports your reading. Stripped of his biological realism, the **Chinese Room** indeed functions as an epistemic argument:

* it denies that **behavioral criteria** (like Turing-style conversation) can reveal consciousness,
* it acknowledges that **we don’t have a theory or test** for consciousness, and
* it insists that **we’re still ignorant of what consciousness fundamentally is**.
